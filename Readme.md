## 机器学习笔记

学习<机器学习>, <统计学习方法>, CS229期间所做的笔记, 并加上一点自己的梳理. 

笔记中有一些笔误, 后面会跟进更正, 希望不会对读者带来较大困扰.

### 笔记

笔记pdf: `ML_note.pdf`

### 涵盖内容

- 线性回归与梯度下降
  - 线性回归
  - LMS与梯度下降法
  - 随机梯度下降法(incremental gradient descent)
  - 批量梯度下降法(batch gradient descent)
  - 线性回归的显式求解
  - 采取最小平方误差作为损失函数的原因
  - 局部加权线性回归
- logistic 回归
  - 梯度下降与logistic回归
  - 牛顿方法
- Fisher线性判别分析
  - 二类线性判别法
- 分类相关问题
  - 多分类学习
    - 一对一策略(One vs One, OvO)
    - 一对其余策略(One vs Rest, OvR)
  - 类别不均衡问题
    - 欠采样(undersampling)
    - 过采样(oversampling)
    - 权值移动(threshold-moving)
- 指数函数族与广义线性模型
  - 伯努利分布导出 logistic 回归
  - 多项式分布导出 softmax 回归.
- 决策树
  - 特征选择
    - 信息增益
    - 信息增益比
    - Gini 指数
  - 决策树的生成
    - ID3
    - C4.5
    - CART
  - 决策树的剪枝
    - 预剪枝
    - 后剪枝
  - 连续值处理
  - 缺失值处理
- 支持向量机
  - 函数间隔与几何间隔
    - 函数间隔
    - 几何间隔
  - 最优间隔分类器
  - 约束优化问题
    - 等式约束优化问题
    - 不等式约束优化问题
  - 最优间隔分类器的求解
  - 核方法
    - 高斯核函数
    - 核的有效性
  - 正则化和非线性可分情况
  - SMO算法
    - 坐标提升
    - SMO
- 学习理论
  - 偏差与方差的权衡
  - 引入
  - 有限假设类$\mathcal{H}$的情况
  - 无限假设类$\mathcal{H}$的情况
    - VC 维
- 正则化与模型选择
  - 交叉验证
    - 留出交叉验证 
    - $k$ 折交叉验证
    - 留一交叉验证 
    - 自助法
  - 性能度量
    - 错误率与精度
    - 查准率、查全率与 F1 
    - ROC 与 AUC
    - 代价敏感错误率与代价曲线 
  - 特征选择.
    - 封装模型特征选择
    - 过滤特征选择
  - 贝叶斯统计与规范化
- 贝叶斯分类器
  - 贝叶斯决策论
  - 极大似然估计
  - 朴素贝叶斯分类器
  - 半朴素贝叶斯分类器 
    - SPODE
    - TAN 
    - AODE
- 附录
  - SVD分解
  - 范数
    - 常用向量范数
    - 常用矩阵范数

#### 参考文献

- 周志华. 机器学习
- 李航. 统计学习方法
- Andrew Ng. Lesson: Stanford CS229

### 编辑与更新该笔记

```
git clone https://github.com/horcham/ML_note
```

- Windows: 直接点击`ML_note.bat`即可编译

- Ubuntu: Terminal输入以下命令即可编译

  ```
  sh ./compile.sh
  ```

#### TODO

- [ ] 该笔记有一些笔误需要更正